{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866162fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4c5ab",
   "metadata": {},
   "source": [
    "# Leer los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74666af9",
   "metadata": {},
   "source": [
    "# PP_SEGMENTADO_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb019a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PP_Segmentado_ABC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_m0 = ['Saldo_total', 'Saldo_Mes', 'Pago_minimo_M0', 'Utilizacion', 'Pago_M0', 'Variable_objetivo', 'Variable_Objetivo_m1', 'L2_Pago', 'dias_deudados_m0', 'Canal_Pago_M1','Canal_Pago_M2','Canal_Pago_M3','Canal_Pago_M4','Canal_Pago_M5','Canal_Pago_M6']\n",
    "\n",
    "df_0 = df.drop(columns = columns_m0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b56f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.get_dummies(df_0, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e59b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[df_1['Saldo_total_M1'].notna()].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df57d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c057267",
   "metadata": {},
   "source": [
    "*Red sencilla*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69547fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver columnas con datos no numéricos\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2.shape)  # (n_filas, n_columnas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['Pago_M1'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5790dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01e11f",
   "metadata": {},
   "source": [
    "# Mejor modelo para PP_Segmentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fijar la semilla para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_2.drop(['Pago_M1'], axis=1).values.astype('float32')  # aseguramos float\n",
    "y = df_2['Pago_M1'].values.astype('float32')\n",
    "\n",
    "# 3. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Dividir en entrenamiento y validación con split aleatorio reproducible\n",
    "n_samples = X_scaled.shape[0]\n",
    "indices = np.random.permutation(n_samples)\n",
    "split = int(0.8 * n_samples)\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# 5. Crear el modelo\n",
    "model_pp = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1)  # Salida para regresión\n",
    "])\n",
    "\n",
    "# 6. Compilar el modelo\n",
    "model_pp.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 7. Entrenar el modelo\n",
    "model_pp.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "loss, mae = model_pp.evaluate(X_val, y_val)\n",
    "print(f'MAE en validación: {mae:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec893d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "with open('modelo_entrenado_pp.pkl', 'wb') as f:\n",
    "    pickle.dump(model_pp, f)\n",
    "\n",
    "\n",
    "##Para cargar el archivo\n",
    "##with open('modelo_entrenado_pp.pkl', 'rb') as f:\n",
    "  ##  resultados_cargados_pp = pickle.load(f)\n",
    "\n",
    "##print(resultados_cargados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_pp.predict(X_val).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "print(\"R2:\", r2_score(y_val, y_pred))\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774291b7",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fijar semilla\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Convertir booleanos a float\n",
    "df_2 = df_2.astype({col: 'float' for col in df_2.select_dtypes('bool').columns})\n",
    "\n",
    "# Preparar datos\n",
    "X = df_2.drop(['Pago_M1'], axis=1).values.astype('float32')\n",
    "y = df_2['Pago_M1'].values.astype('float32')\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Listas para métricas\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# Función para crear modelo (necesario para reiniciar en cada fold)\n",
    "def build_model_pp(input_dim):\n",
    "    model_pp = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1)  # Salida regresión\n",
    "    ])\n",
    "    model_pp.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model_pp\n",
    "\n",
    "# K-Fold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):\n",
    "    print(f\"\\n Fold {fold}\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    model_pp = build_model_pp(X_train.shape[1])\n",
    "    model_pp.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
    "\n",
    "    y_pred = model_pp.predict(X_test).flatten()  # Aplanar para métricas de sklearn\n",
    "    \n",
    "    mae_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    mse_list.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_list.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n📊 Resultados por fold:\")\n",
    "print(\"MAE por fold:\", mae_list)\n",
    "print(\"MSE por fold:\", mse_list)\n",
    "print(\"R² por fold:\", r2_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b77ac4",
   "metadata": {},
   "source": [
    "### Malo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 1413\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_pp.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74334c0",
   "metadata": {},
   "source": [
    "### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 234\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_pp.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa117888",
   "metadata": {},
   "source": [
    "### Bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f48f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 582\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_pp.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d0a61",
   "metadata": {},
   "source": [
    "# TDC_DEPT_SEGMENTADO_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ae577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TDC_D = pd.read_csv('TDC_Dept_Segmentado_ABC.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725eb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TDC_D.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_m0 = ['Saldo_total', 'Saldo_Mes', 'Pago_minimo_M0', 'Utilizacion', 'Pago_M0', 'Variable_objetivo', 'Variable_Objetivo_m1', 'L2_Pago', 'dias_deudados_m0', 'Canal_Pago_M1','Canal_Pago_M2','Canal_Pago_M3','Canal_Pago_M4','Canal_Pago_M5','Canal_Pago_M6']\n",
    "\n",
    "df_0 = df_TDC_D.drop(columns = columns_m0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba12dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.get_dummies(df_0, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_TDC_D = df_1[df_1['Saldo_total_M1'].notna()].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf2ebd",
   "metadata": {},
   "source": [
    "# Mejor modelo para TDC_Dept_Segmentado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fijar la semilla para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "# Separar features y target\n",
    "X = df_2_TDC_D.drop(['Pago_M1'], axis=1).values.astype('float32')  # aseguramos float\n",
    "y = df_2_TDC_D['Pago_M1'].values.astype('float32')\n",
    "\n",
    "# 3. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Dividir en entrenamiento y validación con split aleatorio reproducible\n",
    "n_samples = X_scaled.shape[0]\n",
    "indices = np.random.permutation(n_samples)\n",
    "split = int(0.8 * n_samples)\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# 5. Crear el modelo\n",
    "model_tdc_d = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1)  # Salida para regresión\n",
    "])\n",
    "\n",
    "# 6. Compilar el modelo\n",
    "model_tdc_d.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 7. Entrenar el modelo\n",
    "model_tdc_d.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "loss, mae = model_tdc_d.evaluate(X_val, y_val)\n",
    "print(f'MAE en validación: {mae:.2f}')\n",
    "y_pred = model_tdc_d.predict(X_val).flatten()\n",
    "print(\"R2:\", r2_score(y_val, y_pred))\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea58df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "with open('modelo_entrenado_tdc_d.pkl', 'wb') as f:\n",
    "    pickle.dump(model_tdc_d, f)\n",
    "\n",
    "\n",
    "##Para cargar el archivo\n",
    "##with open('modelo_entrenado_tdc_d.pkl', 'rb') as f:\n",
    "  ##  resultados_cargados_tdc_d = pickle.load(f)\n",
    "\n",
    "##print(resultados_cargados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eedfcef",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90773ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar semilla\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Convertir booleanos a float\n",
    "df_2_TDC_D = df_2_TDC_D.astype({col: 'float' for col in df_2.select_dtypes('bool').columns})\n",
    "\n",
    "# Preparar datos\n",
    "X = df_2_TDC_D.drop(['Pago_M1'], axis=1).values.astype('float32')\n",
    "y = df_2_TDC_D['Pago_M1'].values.astype('float32')\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Listas para métricas\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# Función para crear modelo (necesario para reiniciar en cada fold)\n",
    "def build_model_tdc_d(input_dim):\n",
    "    model_tdc_d = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1)  # Salida regresión\n",
    "    ])\n",
    "    model_tdc_d.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model_tdc_d\n",
    "\n",
    "# K-Fold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):\n",
    "    print(f\"\\n📂 Fold {fold}\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    model_tdc_d = build_model_tdc_d(X_train.shape[1])\n",
    "    model_tdc_d.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
    "\n",
    "    y_pred = model_tdc_d.predict(X_test).flatten()  # Aplanar para métricas de sklearn\n",
    "    \n",
    "    mae_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    mse_list.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_list.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n📊 Resultados por fold:\")\n",
    "print(\"MAE por fold:\", mae_list)\n",
    "print(\"MSE por fold:\", mse_list)\n",
    "print(\"R² por fold:\", r2_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3e0bf",
   "metadata": {},
   "source": [
    "### Malo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cada418",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 83\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_d.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf8652",
   "metadata": {},
   "source": [
    "### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 1562\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_d.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00274d6f",
   "metadata": {},
   "source": [
    "### Bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed039e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 1179\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_d.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd5590",
   "metadata": {},
   "source": [
    "# TDC Visa Segmentado ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TDC_V = pd.read_csv('TDC_Visa_Segmentado_ABC.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TDC_V.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ad31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_m0 = ['Saldo_total', 'Saldo_Mes', 'Pago_minimo_M0', 'Utilizacion', 'Pago_M0', 'Variable_objetivo', 'Variable_Objetivo_m1', 'L2_Pago', 'dias_deudados_m0', 'Canal_Pago_M1','Canal_Pago_M2','Canal_Pago_M3','Canal_Pago_M4','Canal_Pago_M5','Canal_Pago_M6']\n",
    "\n",
    "df_0 = df_TDC_V.drop(columns = columns_m0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.get_dummies(df_0, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_TDC_V = df_1[df_1['Saldo_total_M1'].notna()].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d0ccf2",
   "metadata": {},
   "source": [
    "# Mejor modelo MLP para TDC Visa segmentado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fijar la semilla para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "X = df_2_TDC_V.drop(['Pago_M1'], axis=1).values\n",
    "y = df_2_TDC_V['Pago_M1'].values\n",
    "\n",
    "# 3. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Dividir en entrenamiento y validación con split aleatorio reproducible\n",
    "n_samples = X_scaled.shape[0]\n",
    "indices = np.random.permutation(n_samples)\n",
    "split = int(0.8 * n_samples)\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# 5. Crear el modelo\n",
    "model_TDC_V = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1)  # Salida para regresión\n",
    "])\n",
    "\n",
    "# 6. Compilar el modelo\n",
    "model_TDC_V.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 7. Entrenar el modelo\n",
    "model_TDC_V.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val))\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "loss, mae = model_TDC_V.evaluate(X_val, y_val)\n",
    "print(f'MAE en validación: {mae:.2f}')\n",
    "y_pred = model_TDC_V.predict(X_val).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "print(\"R2:\", r2_score(y_val, y_pred))\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb090b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "with open('modelo_entrenado_tdc_v.pkl', 'wb') as f:\n",
    "    pickle.dump(model_TDC_V, f)\n",
    "\n",
    "\n",
    "##Para cargar el archivo\n",
    "##with open('modelo_entrenado_tdc_v.pkl', 'rb') as f:\n",
    "  ##  resultados_cargados_tdc_v = pickle.load(f)\n",
    "\n",
    "##print(resultados_cargados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556596a",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fijar semilla\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Convertir booleanos a float\n",
    "df_2_TDC_V = df_2_TDC_V.astype({col: 'float' for col in df_2.select_dtypes('bool').columns})\n",
    "\n",
    "\n",
    "# Preparar datos\n",
    "X = df_2_TDC_V.drop(['Pago_M1'], axis=1).values.astype('float32')\n",
    "y = df_2_TDC_V['Pago_M1'].values.astype('float32')\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Listas para métricas\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# Función para crear modelo (necesario para reiniciar en cada fold)\n",
    "def build_model_tdc_v(input_dim):\n",
    "    model_tdc_v = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1)  # Salida regresión\n",
    "    ])\n",
    "    model_tdc_v.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model_tdc_v\n",
    "\n",
    "# K-Fold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):\n",
    "    print(f\"\\n📂 Fold {fold}\")\n",
    "\n",
    "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    model_tdc_v = build_model_tdc_v(X_train.shape[1])\n",
    "    model_tdc_v.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
    "\n",
    "    y_pred = model_tdc_v.predict(X_test).flatten()  # Aplanar para métricas de sklearn\n",
    "    \n",
    "    mae_list.append(mean_absolute_error(y_test, y_pred))\n",
    "    mse_list.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_list.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n📊 Resultados por fold:\")\n",
    "print(\"MAE por fold:\", mae_list)\n",
    "print(\"MSE por fold:\", mse_list)\n",
    "print(\"R² por fold:\", r2_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fcce3",
   "metadata": {},
   "source": [
    "### Malo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc829d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 122\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_v.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91dbc93",
   "metadata": {},
   "source": [
    "### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 1382\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_v.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f22197",
   "metadata": {},
   "source": [
    "### Bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "registro_n = 128\n",
    "punto_original = X[registro_n].reshape(1, -1) \n",
    "\n",
    "# Escalar el punto individual\n",
    "punto_escalado = scaler.transform(punto_original)\n",
    "\n",
    "# Usar el último modelo del último fold\n",
    "prediccion = model_tdc_v.predict(punto_escalado).flatten()[0]\n",
    "\n",
    "print(f\"Predicción del modelo para el registro {registro_n}: {prediccion:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2efb6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
